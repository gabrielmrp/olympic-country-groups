import warnings
import numpy as np
import json
import pandas as pd
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import geopandas as gpd
import streamlit as st
from features_functions import def_gender,get_feature_total_medals,get_feature_gold_medals,get_feature_gender,get_feature_collective,get_feature_categories_diverse
from display_functions import print_23d_clusters,show_feature_to_pca,create_cluster_feature_heatmap,generate_map,crop_image,elbow_chart
from st_aggrid import AgGrid, GridOptionsBuilder
    

warnings.filterwarnings("ignore", category=DeprecationWarning)
warnings.filterwarnings("ignore", category=FutureWarning, message=".*geopandas.dataset.*")

pd.set_option('display.max_rows', None)


def apply_kmeans(optimal_k,df_features,name_symbol_dict):
    # Selecionar todas as colunas num√©ricas 
    # Normalizar os dados
    scaler = StandardScaler()
    scaled_features = scaler.fit_transform(df_features)

    # Aplicar o K-means
    kmeans = KMeans(n_clusters=optimal_k, random_state=0)
    clusters = kmeans.fit_predict(scaled_features)

    return clusters,scaled_features



def map_symbols_to_clusters(df_by_country,labels,name_symbol_dict):
    df_sym_cluster = pd.DataFrame()
    dict_country_label = { l:[] for l in labels }

    for i in range(len(df_by_country.Cluster.value_counts())):

        dict_country_label[labels[i]] = df_by_country[df_by_country.Cluster == i].sort_values(['name'])['name'].tolist()
        #for country in range(pd.DataFrame(df_by_country[df_by_country.Cluster == i])):
        #    #st.write(country)
        #    #dict_country_label[labels[i]].append(country['name'])

        aux = pd.DataFrame(df_by_country[df_by_country.Cluster == i]['name'].map(name_symbol_dict)).set_index('name')
        aux['Cluster']  = i
        df_sym_cluster = pd.concat([df_sym_cluster,aux])
    df_sym_cluster=df_sym_cluster.reset_index()
 
    return df_sym_cluster,dict_country_label



def fill_groups(df_sym_cluster):

    # Baixar o shapefile do mundo
    # TODO utilizar outra forma de obter o modelo, pois s√≥ funciona na vers√£o <1 do geopandas
    world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))


    # Dicion√°rio de substitui√ß√£o de c√≥digos ISO
    with open('config/symbols.json', 'r', encoding='utf-8') as file:
        symbols_rep = json.load(file)

    excluded = ['HKG', 'SGP', 'EOR', 'LCA', 'GRN', 'CPV', 'DMA']

    # Adicionar colunas de grupo
    world['Group'] = None

    # Mapear os pa√≠ses para o mundo
    for _,row in df_sym_cluster.iterrows():
        country = row['name']
        group = row['Cluster']
        if country not in excluded and (country in world['iso_a3'].values or country in symbols_rep.keys()):
            if country in symbols_rep.keys():
                country = symbols_rep[country]
            world.loc[world['iso_a3'] == country, 'Group'] = group

        else:
            if country in excluded:
                pass
            else:
                pass
                #print(country)

    return world

if __name__ == "__main__": 

    st.set_page_config(page_title="Perfis de Pa√≠ses de Acordo com o Desempenho Ol√≠mpico", page_icon="ü•á")
    show = True

    st.markdown(
    """
    <style>
        .label_0{color:orange}
        .label_1{color:yellow}
        .label_2{color:red}
        .label_3{color:whitesmoke}
        .label_4{color:blue}
        .label_5{color:brown}
        .label_6{color:purple}
        .label_7{color:green}
        .country{color:#a1a1a1!important}
        ol {
            list-style-type: decimal; /* Ensure list items are numbered */
        }
        *{text-align: justify;}
        h1{text-align:center}
        h2,h3{text-align:left}
        .techinfo{color: lightblue;margin-left:2em}
        .alert{color: yellow}
        ul { margin: 0}

    </style>

    """,
    unsafe_allow_html=True) 
 
 
    # L√™ os nomes das categorias
    with open('config/categories.json', 'r', encoding='utf-8') as file:
        categories = json.load(file)


    # L√™ os nomes dos grupos
    with open('config/labels.json', 'r', encoding='utf-8') as file:
        labels = json.load(file)
 
    # L√™ os nomes das features
    with open('config/features.json', 'r', encoding='utf-8') as file:
        feature_names = json.load(file)  

    st.title('Perfis de Pa√≠ses de Acordo com o Desempenho Ol√≠mpico')

    st.write('Neste projeto de ci√™ncia de dados, utilizamos um algoritmo de clusteriza√ß√£o para identificar grupos de delega√ß√µes esportivas nas Olimp√≠adas de Paris 2024, com base em caracter√≠sticas de desempenho.')

    st.write('Inicialmente, detalharemos o banco de dados utilizado e seu processo de constru√ß√£o. Em seguida, mostraremos as caracter√≠sticas usadas para identificar os perfis. Posteriormente, aplicaremos o algoritmo de clusteriza√ß√£o e apresentaremos os grupos formados por meio de gr√°ficos de dispers√£o e de um Mapa.')

    st.markdown('<p class="alert">‚ö†Ô∏è Importante, Importante: o √≠cone ‚úçÔ∏è indica que a leitura destacada cont√©m detalhes mais t√©cnicos, podendo ser pulada sem preju√≠zo para o entendimento geral.', unsafe_allow_html=True)

    st.markdown('<p class="techinfo">‚úçÔ∏è Para esse projeto utilizamos a linguagem Python e as bibliotecas: pandas e geopandas (manipula√ß√£o de base de dados) scikit-learn (machine learning); plotly, matplotlib e seaborn (visualiza√ß√£o) e tamb√©m o streamlit para a apresenta√ß√£o. O c√≥digo se encontra ao final da p√°gina.</p>', unsafe_allow_html=True)

    st.divider()
    st.header('Base de dados:')
    st.markdown('A base de dados foi montada a partir da coleta dos dados diretamente do <a href="https://olympics.com/pt/paris-2024/medalhas">site oficial das Olimp√≠adas Paris 2024</a>.', unsafe_allow_html=True)

    st.markdown('<p class="techinfo">‚úçÔ∏è O processo de web scraping para a coleta dos dados foi realizado de maneira semi-autom√°tica, e seu detalhamento est√° al√©m do escopo desta apresenta√ß√£o.</p>', unsafe_allow_html=True)

 

    # Abre o dataframe com todos os dados
    df = pd.read_excel('olympic_medal_table_2024_v1.xlsx', index_col=0)

    st.write('Os dados apresentados na tabela de medalhas s√£o organizados em tr√™s n√≠veis: Pa√≠ses, Esporte e Medalha, com cada linha representando uma medalha. Abaixo, vamos exemplificar esses n√≠veis usando como exemplo a medalha de ouro de Rebeca Andrade no solo.')

    # L√™ os nomes dos pa√≠ses a serem substituidos

    def st_show_dataframe_compacted(series_aux, columns):
        df_aux = pd.DataFrame(series_aux).T
        df_aux = df_aux[columns]
        st.dataframe(df_aux)

 
    st.write('Pa√≠s')   

    st_show_dataframe_compacted(df.iloc[722],['symbol','name','gold','silver','bronze','total_medals','score_position'])

    st.write('Esporte')   
    st_show_dataframe_compacted(df.iloc[722],['sport_position','sport','sport_gold','sport_silver','sport_bronze','total_medals_sport'])

    st.write('Medalha') 
    st_show_dataframe_compacted(df.iloc[722],['modality','athlete','medal'])

    st.write('Decidiu-se, para facilitar a an√°lise, manter a tabela na forma n√£o-normalizada. Ou seja, para o Brasil, todas as linhas repetir√£o as informa√ß√µes atribu√≠das ao pa√≠s. Da mesma forma, as informa√ß√µes sobre a Gin√°stica Art√≠stica do Brasil tamb√©m ser√£o replicadas em todas as linhas referentes √†s medalhas brasileiras desse esporte.')

    with open('config/country_names.json', 'r', encoding='utf-8') as file:
        country_rep = json.load(file)
    df['name'] = df['name'].map(lambda x:country_rep[x] if x in country_rep.keys() else x)


    st.divider()

    st.subheader('Categorias selecionadas.')

    st.write('Com os dados em m√£os, foram determinados cinco crit√©rios (passaremos a chamar tamb√©m de _Features_) para definir os grupos (passaremos a chamar tamb√©m de _Clusters_) de delega√ß√µes, com base em semelhan√ßas nos perfis de medalhas:')

    st.markdown("<ul>", unsafe_allow_html=True)
    st.markdown("<li> Total de Medalhas ü•áü•àü•â</li>", unsafe_allow_html=True)
    st.markdown("<li> Percentual de Medalhas de Ouro ü•á‚ûóü•áü•àü•â</li>", unsafe_allow_html=True)
    st.markdown("<li> Percentual de Medalhas em Modalidades Femininas üë©‚ûóüë•</li>", unsafe_allow_html=True)
    st.markdown("<li> Percentual de Medalhas em Modalidades Coletivas üë•‚ûóüë§üë•</li>", unsafe_allow_html=True)
    st.markdown("<li> N√∫mero de Medalhas em Diferentes Categorias üèåüèª‚õπüèæü§∏üèæüèãüèª </li>", unsafe_allow_html=True)
    st.markdown("</u>", unsafe_allow_html=True)


    st.write('Passamos, ent√£o, a direcionar nosso foco para a an√°lise da tabela sob a perspectiva de cada pa√≠s, realizando opera√ß√µes matem√°ticas para calcular os valores mencionados anteriormente.') 

    # Extrai os detalhes das features
    df['categories'] = df['sport'].map(categories)
    df['gender'] = df.modality.str.lower().map(def_gender)
    df['collective'] = df['athlete'].map({'Team':'team'}).fillna('individual')
 
    # Cria o dataframe por pais 
    df_by_country = df[['name','gold','total_medals']].drop_duplicates().reset_index(drop=True)

    # Coleta as features
    get_feature_total_medals(df_by_country)
    get_feature_gold_medals(df_by_country)

    df_by_country.drop(['total_medals','gold'], axis=1, inplace=True)

    df_by_country = get_feature_gender(df,df_by_country)
    df_by_country = get_feature_collective(df,df_by_country)
    df_by_country = get_feature_categories_diverse(df,df_by_country)

    # Cria os dicion√°rios de convers√£o de s√≠mbolo para nome de pa√≠s e vice-versa
    name_symbol_dict = df.groupby(['name', 'symbol']).count()['sport'].reset_index()[['name', 'symbol']].set_index('name').to_dict()['symbol']
    symbol_name_dict = {v: k for k, v in name_symbol_dict.items()}
 
    df_features = df_by_country.copy()
    df_features = df_features.reset_index().drop('index', axis=1).set_index('name') 
    df_features.index = df_features.index.map(name_symbol_dict)

    
    st.write('Em rela√ß√£o aos crit√©rios de totaliza√ß√£o, especificamente o primeiro e o √∫ltimo, realizaremos a normaliza√ß√£o com base nos maiores valores observados em ambos.')

    st.write('Agora estamos prontos para come√ßar a aplicar as t√©cnicas de machine learning para identificar os perfis de pa√≠ses.')

    st.divider()

    st.title('Aplica√ß√£o de T√©cnicas de Machine Learning')


    st.subheader('Escolha do n√∫mero de grupos a serem formados')

    st.write('Para iniciarmos a identifica√ß√£o dos clusters, √© essencial determinar a quantidade ideal. Um n√∫mero muito baixo pode resultar em grupos heterog√™neos e pouco representativos. Por outro lado, uma quantidade muito alta pode tornar a an√°lise excessivamente espec√≠fica e menos eficaz.')


    st.markdown('<p class="techinfo">‚úçÔ∏è Uma an√°lise que pode nos ajudar nessa decis√£o √© a observa√ß√£o do gr√°fico do tipo "cotovelo" (elbow). Esse gr√°fico indica a faixa em que o n√∫mero ideal de clusters pode ser encontrado. Por meio de uma s√©rie de simula√ß√µes, o gr√°fico nos mostra a variabilidade interna de acordo com o n√∫mero de clusters, indicando o ponto em que adicionar mais clusters n√£o resulta em melhorias significativas na separa√ß√£o dos dados. <br /><br />No gr√°fico abaixo, podemos observar exatamente isso. Inicialmente, a variabilidade interna √© muito alta, mas a redu√ß√£o das diverg√™ncias internas √© significativa at√© o 7¬∫ cluster, tornando-se m√≠nima a partir desse ponto.</p>', unsafe_allow_html=True)



    st.write('Com base no gr√°fico do cotovelo e na observa√ß√£o dos agrupamentos obtidos, definimos o uso de 8 grupos para esta an√°lise.')

    elbow_chart(df_features,show)

    # N√∫mero de clusters escolhido (exemplo: 8)
    optimal_k = 8

    st.subheader('Aplicando do algoritmo de Clusteriza√ß√£o e visualiza√ß√£o dos grupos')

    st.write('Prossegue-se ent√£o para a realiza√ß√£o da aplica√ß√£o do algor√≠tmo de clusteriza√ß√£o: o KMeans.')

    st.markdown('<p class="techinfo">‚úçÔ∏è Este algoritmo opera da seguinte forma: √© definido um ponto central para representar cada um dos oito grupos e atribui cada elemento (neste caso, pa√≠ses) ao grupo mais pr√≥ximo. Em seguida, recalcula a posi√ß√£o do ponto central de cada grupo, ajustando-o para a posi√ß√£o m√©dia dos elementos atribu√≠dos ao grupo. Ap√≥s isso, √© revisto o grupo a qual cada elemento pertence com base na novas posi√ß√µes dos centros. Esse processo √© repetido at√© que essas posi√ß√µes n√£o mudem mais.</p>', unsafe_allow_html=True)
    
    # Aplica o m√©todo de clusteriza√ß√£o
    clusters,scaled_features  = apply_kmeans(optimal_k,df_features,name_symbol_dict)

    # Adicionar os clusters ao DataFrame de pa√≠ses
    df_by_country['Cluster'] = clusters
    df_by_country['Symbol'] = df_features.index

    st.write('Algoritmo aplicado, agora vamos ver como ficou!')

    st.write('Para a visualiza√ß√£o dos grupos formados, um passo adicional √© necess√°rio, j√° que o algoritmo de clusteriza√ß√£o gera resultados em dimens√µes superiores √†s que podemos enxergar. Portanto, precisamos representar os clusters em 2 dimens√µes (plano) ou 3 dimens√µes (espa√ßo). Para isso, utilizamos a t√©cnica chamada PCA (Principal component Analysis).')

    st.markdown('<p class="techinfo">‚úçÔ∏è O PCA √© respons√°vel por "achatar" um espa√ßo multidimensional em dimens√µes menores, mantendo o m√°ximo de variabilidade dos dados. Para alcan√ßar isso, o PCA realiza uma transforma√ß√£o matem√°tica baseada em uma combina√ß√£o das vari√°veis originais. Esta transforma√ß√£o √© feita atrav√©s da soma ponderada dos valores de cada uma das caracter√≠sticas (features).</p>', unsafe_allow_html=True)
    
    st.write('Podemos afirmar que o PCA pode ser utilizado para substituir as features na representa√ß√£o dos dados, pois cada componente principal √© uma combina√ß√£o das vari√°veis originais. No gr√°fico abaixo, podemos ver a contribui√ß√£o de cada feature para a forma√ß√£o de cada componente principal (PC1, PC2 e PC3). ')

    # Mostra o crit√©rio de relev√¢ncia de feature por cluster
    show_feature_to_pca(scaled_features,feature_names,show)

    st.write('Vamos analisar como o PC1 (Primeiro Componente Principal) √© formado a partir dos valores das features. Esse racioc√≠nio pode ser estendido para os outros componentes principais. Conforme detalhado na tabela acima, temos que:')
    st.code('PC1=0.6*[N¬∫ Medalhas]+0.2*[% de Ouros]+0.3*[% Feminino]-0.4["% Mod. Coletivas]+0.6[N¬∫ Categorias]')

    st.write('Agora que explicamos a necessidade do uso do PCA e mostramos como ele √© formado a partir dos valores das features, estamos prontos para representar os dados em um gr√°fico de duas dimens√µes, utilizando o PC1 e o PC2. Veja o resultado:')
    # Mostra os cluster em um espa√ßo 2d
    print_23d_clusters(df_by_country,scaled_features,name_symbol_dict,labels,2,show)

    st.write('Visualizamos agora os oito clusters formados e seus respectivos integrantes com base em suas localiza√ß√µes nos eixos dos dois primeiros componentes principais (PC1 e PC2).') 

    st.write('A partir da dispers√£o apresentada, √© poss√≠vel perceber que alguns grupos, como os clusters 4, 5 e 8, podem ser facilmente separados dos demais. No entanto, a separa√ß√£o de outros grupos n√£o √© t√£o simples, pois eles est√£o emaranhados em uma regi√£o espec√≠fica do gr√°fico.')

    st.write('Observando os pa√≠ses que comp√µem esse conjunto e lembrando que o PC1 (no eixo horizontal) √© fortemente influenciado pelo n√∫mero de medalhas, podemos concluir que esse conjunto de grupos √© composto por pa√≠ses com poucas medalhas.')  

    st.write('Devido a essa dificuldade de separa√ß√£o, a representa√ß√£o em duas dimens√µes n√£o √© suficiente para definir claramente os limites desses clusters. Para uma visualiza√ß√£o mais eficaz, precisamos adicionar pelo menos mais uma dimens√£o. Vamos ent√£o explorar o espa√ßo tridimensional.') 


    st.write('Ao adicionar o terceiro componente (PC3), conseguimos realizar a representa√ß√£o espacial dos dados. Assim, podemos explorar melhor a disposi√ß√£o dos clusters e pa√≠ses, e a separa√ß√£o entre eles torna-se muito mais evidente.')

    st.markdown('<p class="alert">‚ö†Ô∏è Para explorar o gr√°fico abaixo, navegue por ele utilizando o bot√£o esquerdo do mouse para girar e o scroll para dar zoom ou recolher, ou ent√£o, use os controles fornecidos', unsafe_allow_html=True) 
    

    # Mostra os cluster em um espa√ßo 3d
    print_23d_clusters(df_by_country,scaled_features,name_symbol_dict,labels,3,show)
  

    st.markdown('<p class="techinfo">‚úçÔ∏è A maior capacidade de separar visualmente os grupos ocorre porque, como mostrado na tabela acima, a adi√ß√£o de uma terceira dimens√£o aumenta a capacidade do PCA de representar a variabilidade dos dados. Esse √≠ndice √© conhecido como vari√¢ncia explicada cumulativa.</p>', unsafe_allow_html=True) 

    st.write('Percebeu que foram adicionados nomes aos clusteres, vou explicar a partir do gr√°fico abaixo como chegamos nessa nomenclatura.') 

    st.divider()

    st.subheader('Atribui√ß√£o de nomes aos grupos encontrados') 

    st.write('O gr√°fico do tipo mapa de calor (heatmap) utiliza cores para representar os valores, onde cores mais quentes indicam valores mais altos. No nosso caso, estamos analisando a m√©dia de cada feature por cluster em compara√ß√£o com a m√©dia global de cada feature.') 
        
    # Mostra o heatmat de relev√¢ncia de feature por cluster
    create_cluster_feature_heatmap(df_features,feature_names,df_by_country,labels,show)
     

    st.write('Por meio de inspe√ß√£o visual, podemos analisar quais s√£o as features mais marcantes em um cluster, tanto do ponto de vista de valores baixos (pr√≥ximo de 0), quanto no caso de valores altos (maior que 1).')

    st.write('De imediato, √© vis√≠vel que o cluster 4 se refere √†s "Superpot√™ncias Ol√≠mpicas", devido ao alto n√∫mero de medalhas e √† diversidade de categorias esportivas nas quais as delega√ß√µes integrantes conquistaram medalhas. O processo de defini√ß√£o de nomes prossegue para os demais grupos sempre com base em suas caracter√≠sticas marcantes.')

    # Compatibiliza√ß√£o do s√≠mbolo para gerar o mapa
    df_sym_cluster,dict_country_label = map_symbols_to_clusters(df_by_country,labels,name_symbol_dict)
    world = fill_groups(df_sym_cluster)

    st.divider()

    st.title('Cria√ß√£o do Mapa colorido pelos grupos')
    
    st.write('O passo final √© gerar o mapa colorido pelas cores dos grupos de pa√≠ses identificados com base nas suas caracter√≠sticas olimpicas. Veja como ficou!')
    
    generate_map(world,optimal_k,labels,show)

    
    st.markdown("Abaixo est√£o detalhados os pa√≠ses existentes em cada grupo:<ul>", unsafe_allow_html=True)
    for i in range(len(dict_country_label)):
        label = list(dict_country_label.keys())[i]
        st.markdown("<li  class='label_"+str(i)+"'><b>"+label+": </b><span class='country'>"+"; ".join(dict_country_label[label])+".<span></li>", unsafe_allow_html=True)
    st.markdown("</ul>", unsafe_allow_html=True)    

    st.markdown('<small>Obs. O grupo "Conquistas Femininas no Caribe" n√£o est√° representado no gr√°fico por conta da dimens√£o das ilhas.</small>', unsafe_allow_html=True)
 
    st.write('Chegamos ao final deste projeto, demonstrando que √© poss√≠vel realizar uma an√°lise diferenciada a partir do quadro de medalhas. A pergunta que fica √© se, na pr√≥xima edi√ß√£o das Olimp√≠adas, essas caracter√≠sticas v√£o se manter ou teremos grandes mudan√ßas.') 

    st.write('Ser√° que finalmente veremos o Brasil ser inclu√≠do no grupo dos "Supermedalhistas Multimodais"?')

    st.link_button('Veja o c√≥digo no github', 'https://github.com/gabrielmrp/olympic-country-groups', type="secondary")


    # TODO remover os eixos sem precisar cortar as imagens
    #crop_image(show)
